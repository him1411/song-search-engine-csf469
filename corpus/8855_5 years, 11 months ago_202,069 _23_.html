I want to perform my own complex operations on financial data in dataframes in a sequential manner.For example I am using the following MSFT CSV file taken from Yahoo Finance:I then do the following:Is that the most efficient way? Given the focus on speed in pandas, I would assume there must be some special function to iterate through the  values in a manner that one also retrieves the index (possibly through a generator to be memory efficient)? df.iteritems unfortunately only iterates column by column.The newest versions of pandas now include a built-in function for iterating over rows. Or, if you want it faster use itertuples()But, unutbu\'s suggestion to use numpy functions to avoid iterating over rows will produce the fastest code. Pandas is based on NumPy arrays.\nThe key to speed with NumPy arrays is to perform your operations on the whole array at once, never row-by-row or item-by-item.For example, if close is a 1-d array, and you want the day-over-day percent change,This computes the entire array of percent changes as one statement, instead of So try to avoid the Python loop for i, row in enumerate(...) entirely, and\nthink about how to perform your calculations with operations on the entire array (or dataframe) as a whole, rather than row-by-row.You can loop through the rows by transposing and then calling iteritems:I am not certain about efficiency in that case. To get the best possible performance in an iterative algorithm, you might want to explore writing it in Cython, so you could do something like:I would recommend writing the algorithm in pure Python first, make sure it works and see how fast it is-- if it\'s not fast enough, convert things to Cython like this with minimal work to get something that\'s about as fast as hand-coded C/C++.Like what has been mentioned before, pandas object is most efficient when process the whole array at once. However for those who really need to loop through a pandas DataFrame to perform something, like me, I found at least three ways to do it. I have done a short test to see which one of the three is the least time consuming.Result:This is probably not the best way to measure the time consumption but it\'s quick for me.Here are some pros and cons IMHO:I checked out iterrows after noticing Nick Crawford\'s answer, but found that it yields (index, Series) tuples. Not sure which would work best for you, but I ended up using the itertuples method for my problem, which yields (index, row_value1...) tuples.There\'s also iterkv, which iterates through (column, series) tuples.Just as a small addition, you can also do an apply if you have a complex function that you apply to a single column:http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.apply.htmlAnother suggestion would be to combine groupby with vectorized calculations if subsets of the rows shared characteristics which allowed you to do so. 